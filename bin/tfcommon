#!/usr/bin/env bash +x

## INIT for all uses
TERRAFORM_AWS_BACKEND_PROFILE=s3-profile
TERRAFORM_BACKEND_BUCKET=cookson-pro-tf-backend
AWS_DEPLOY_PROFILE=oidc-profile

# Centralise folder detection since it can be "folder" or "folder/env"
export folder=${1:-.}

# If folder contains a slash, split it to vars "folder" and "env"
if [[ "$folder" == *"/"* ]]; then
  export env=$(basename "$folder")
  export folder=$(dirname "$folder")
else
  export env=""
fi

echo "Startup, detected: folder ${folder}, env ${env}"

# check existence of terraform binary
if ! type terraform >/dev/null 2>&1; then
  echo "terraform not found in PATH"
  exit 1
fi

terraform --version

# use local folder for backend, override ~/.tfbackend with env BACKEND_PATH
backend_path=${BACKEND_PATH:-~/.tfbackend}
if [ ! -d "$backend_path" ]; then
  mkdir -p "$backend_path"
fi

# check for a command line parameter --reconfigure in any position and set variable reconfigure=true
if [[ " $* " == *" --reconfigure "* ]]; then
  reconfigure=true
fi

# make this a CLI option to (rarely) do a reconfigure, do migrate-state by default
if [[ $reconfigure == true ]]; then
  export TF_CLI_ARGS_init="-compact-warnings -upgrade -reconfigure"
else
  export TF_CLI_ARGS_init="-compact-warnings -upgrade -migrate-state"
fi

## Functions
is_tf_folder() {
  local folder="$1"

  if [[ ! -d "$folder" ]]; then
    echo "Error: '$folder' is not a valid directory."
    return 1
  fi

  status=1
  find "$folder" -maxdepth 1 -type f -name "*.tf" -print -quit 2>/dev/null | grep . >/dev/null

  if [[ $? -eq 0 ]]; then
    return 0
  else
    echo "No files with extension 'tf' found in '$folder'."
    return 1
  fi
}

## Returns 0 if logged in, 1 if call fails
_isbackendloggedin() {
  echo "Checking AWS backend login status (profile ${TERRAFORM_AWS_BACKEND_PROFILE})..."
  aws sts get-caller-identity --profile ${TERRAFORM_AWS_BACKEND_PROFILE} >/dev/null 2>&1
  return $?
}

# setupbackend <project_name>
#     current directory will be "folder" for this action
setupbackend() {
  project_name=$1
  folder=$(basename $PWD)
  key_path=${folder}
  [[ "$env" != "" ]] && key_path="$folder/$env"

  _isbackendloggedin || { echo "Not logged in to AWS, cannot set up S3 backend $?"; exit 1; }
  # echo ==============
  # echo "$TERRAFORM_AWS_BACKEND_PROFILE"
  # echo "$TERRAFORM_BACKEND_BUCKET"
  # echo "$AWS_DEPLOY_PROFILE"
  # echo ==============

  # For CI/CD, use an assumable role, assume circleci role for now
  # make profile dynamic
  cat <<EOF >work/_backend.tf
  terraform {
    backend "s3" {
      bucket = "${TERRAFORM_BACKEND_BUCKET}"
      key    = "${project_name}/${key_path}"
      use_lockfile = true
      region = "us-east-1"
      profile = "${TERRAFORM_AWS_BACKEND_PROFILE}"
    }
  }
EOF
  echo "S3 Backend Set Up: ${project_name}/${key_path}"
  # cat work/_backend.tf
}

detectnpmbuild() {
  # Check if package.json exists in the current directory
  if [[ -f "package.json" ]]; then
    build_script=$(npm pkg get scripts.build_lambda 2>/dev/null)

    if [[ "$build_script" != "{}" ]] && [[ -n "$build_script" ]]; then
      echo "Build script found in package.json: $build_script"
      return 0
    else
      # echo "No 'build' script found in package.json."
      return 1
    fi

    return 0
  else
    # echo "Not an npm project"
    return 1
  fi
}

# Require poetry installed for python lambdas
detectpoetrybuild() {
  # Check if package.json exists in the current directory
  if [[ -f "package.json" ]]; then
    build_script=$(npm pkg get scripts.build_lambda 2>/dev/null)

    if [[ "$build_script" != "{}" ]] && [[ -n "$build_script" ]]; then
      echo "Build script found in package.json: $build_script"
      return 0
    else
      # echo "No 'build' script found in package.json."
      return 1
    fi

    return 0
  else
    # echo "Not an npm project"
    return 1
  fi
}

installlambdas() {
  # Clone lambda repositories if LAMBDA_REPOS is set
  # "npm run build_lambda" must produce a lambda.zip in the repo's folder
  if [[ -n "$LAMBDA_REPOS" ]]; then
    echo "Cloning and building lambda repos"
    # Split LAMBDA_REPOS by comma and iterate over each repo
    IFS=',' read -ra repos <<<"$LAMBDA_REPOS"
    for repo in "${repos[@]}"; do
      echo "Cloning lambda repo: $repo"
      git clone "$repo"
      # run npm instal and build for each repo
      repo_name=$(basename "$repo" .git)
      if [[ -d "$repo_name" ]]; then
        pushd "$repo_name"
        if [[ detectnpmbuild -eq 0 ]]; then
          echo "Detected npm project in $repo_name, running npm install and build"
          npm install && npm run build_lambda
        else
          echo "Skipping lambda install"
        fi
        popd # go back to the work folder
      fi
    done
  fi
}

loadjobvars() {
  echo "Loading job variables from $PWD"
  # Load job variables from the environment or a file
  if [[ -f "job.vars" ]]; then
    echo " > Loading $folder/job.vars"
    source job.vars
  elif [[ -f ".env" ]]; then
    echo " > Loading $folder/.env"
    source .env
  fi

  # if job.vars is in folder/env, load those, with higher precedentt than file in folder
  if [[ -f "envs/$env/job.vars" ]]; then
    echo " > Loading $folder/envs/$env/job.vars"
    source "envs/$env/job.vars"
  elif [[ -f "envs/$env/.env" ]]; then
    echo " > Loading $folder/$envs/env/.env"
    source "envs/$env/.env"
  fi

  # Check if LAMBDA_REPOS is set, if not, set it to an empty string
  LAMBDA_REPOS=${LAMBDA_REPOS:-""}
}

# setupworkfolder <folder>
#     currend directory has to be main project root
setupworkfolder() {
  local folder="$1"

  if [[ -d "$folder/work" ]]; then
    echo "Removing old work files"
    rm -fr "$folder/work" # wipe all work files
  fi

  echo "Setting up $folder"
  if [[ ! -d "$folder/work" ]]; then
    echo "Creating work folder for $folder"
    mkdir -p "$folder/work"
  else
    echo " ********> Work folder already exists for $folder"
  fi
  # TODO: make this circle-ci agnostic
  local project_name=${CIRCLE_PROJECT_REPONAME:-$(basename $PWD)}

  echo "Project Name: $project_name"
  cd "$folder"

  loadjobvars

  setupbackend "$project_name" || { echo "Backend Setup Failed"; return 1; }

  # Find directories directly under the current path (.), at depth 1.
  # -type d: only directories.
  # ! -name '*.*': directory name does not contain a dot. This excludes hidden folders (e.g. .git) and folders with dots (e.g. my.folder).
  # ! -name 'work': exclude the 'work' directory itself.
  # -print: prints the found path.
  # Errors (e.g., permission denied) are suppressed.
  local found_folders
  found_folders=$(find . -maxdepth 1 -type d ! -name '*.*' ! -name 'work' ! -name 'envs' -print 2>/dev/null)

  [[ ! -z "$found_folders" ]] && echo "Folders to symlink into 'work': $found_folders"
  # symlink any non-dot folders to work, mainly for static or auxilliary files
  for folder_path in $found_folders; do
    local dir_name
    dir_name=$(basename "$folder_path") # Extracts 'gcp' from './gcp'

    if [[ -n "$dir_name" ]]; then # Ensure dir_name is not empty
      echo "Symlinking ../$dir_name to work/$dir_name"
      # Create a relative symlink inside the 'work' directory.
      # ln -sfn TARGET LINK_NAME
      # TARGET is ../$dir_name (relative to the 'work' directory)
      # LINK_NAME is work/$dir_name
      # -f: force (overwrite if exists)
      # -n: no-dereference (if work/$dir_name is a symlink to a dir, replace the symlink itself)
      ln -sfn "../$dir_name" "work/$dir_name"
    fi
  done

  [[ -n "$INCLUDE_ZIPS" ]] && cp *.zip work
  
  cp *.tf terraform.tfvars work 2>/dev/null

  # If var env is not empty, copy from that folder also
  [[ "$env" != "" ]] && [[ -d "envs/$env" ]] && cp envs/${env}/*.tf envs/${env}/terraform.tfvars work 2>/dev/null
  
  cd work

  installlambdas

  getcreds

  echo "Running terraform commands in ${PWD}"
}

## Returns 0 if logged in, 1 if call fails
_isawsloggedin() {
  echo "Checking AWS deploy login status (profile ${AWS_DEPLOY_PROFILE})..."
  aws sts get-caller-identity --profile ${AWS_DEPLOY_PROFILE} >/dev/null 2>&1
  return $?
}

getawscreds() {
  local aws_found=0
  grep aws provider.tf 2>/dev/null >/dev/null
  if [[ $? == 0 ]]; then
    aws_found=1
  fi
  grep s3 backend.tf 2>/dev/null >/dev/null
  if [[ $? == 0 ]]; then
    aws_found=1
  fi

  if [[ ${aws_found} -eq 0 ]]; then
    return 0
  fi

  echo "Detected AWS provider"
  
  # Check for access via AWS_DEPLOY_PROFILE, use oidc to log in for AWS deploy access
  _isawsloggedin || { echo "Not logged in to AWS, cannot deploy. Log into ${AWS_DEPLOY_PROFILE} to obtain credentials"; exit 1; }

  # NOTE: locally and on circleci, backend uses TERRAFORM_AWS_BACKEND_PROFILE explicitly, and terraform plan/apply uses AWS_DEPLOY_PROFILE explicitly
  echo "Using AWS profile ${AWS_DEPLOY_PROFILE} to deploy"
  export AWS_PROFILE=${AWS_DEPLOY_PROFILE}
}

getazurecreds() {
  # echo "Checking AZURE creds $(grep azurerm provider.tf)"
  grep azurerm provider.tf 2>/dev/null >/dev/null
  if [[ ! $? -eq 0 ]]; then
    return 0
  fi

  echo "Detected Azure template"

  authjson=$(az account list 2>/dev/null)
  export ARM_SUBSCRIPTION_ID=$(echo "$authjson" | jq -r .[0].id)
  export ARM_TENANT_ID=$(echo "$authjson" | jq -r .[0].tenantId)

  echo "Tenant ID $ARM_TENANT_ID"
  echo "Subscription ID $ARM_SUBSCRIPTION_ID"
}

# GCP depends on the CLI gcloud being logged in, so that's a pre-requisite for now
getcreds() {
  getawscreds
  getazurecreds
}
